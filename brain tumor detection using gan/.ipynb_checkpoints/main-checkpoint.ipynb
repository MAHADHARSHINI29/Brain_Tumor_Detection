{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPnRE34GaJfw"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "gVeRC6aeaJfy"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfT8PyiRaJfz"
   },
   "outputs": [],
   "source": [
    "class_names = ['fake fifty', 'fifty original','five hundred fake', 'fivehund original', 'hund fake', 'hundred original', 'ten fake', 'ten original', 'twenty fake', 'twenty original', 'two hund fake', 'two thousand fake',\n",
    "              'twohund original','twothousand original']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GnWSIhzaJfz"
   },
   "source": [
    "# Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d684vIT_aJfz"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    datasets = [r\"C:\\Users\\TGA\\Music\\reptile identification using GAN\\train\", r\"C:\\Users\\TGA\\Music\\reptile identification using GAN\\test\"]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        print(\"Loading {}\".format(dataset))\n",
    "\n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "\n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "\n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "\n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaUtXn7-aJf0",
    "outputId": "6210690b-7723-41d4-93ca-b164ba6ff195"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt_whTHjaJf0"
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVk4qT3JaJf0",
    "outputId": "c222462f-c397-4d39-ce94-9110589abebd"
   },
   "outputs": [],
   "source": [
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each image is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "y84npp_faJf1",
    "outputId": "ac69b741-7d62-4d71-b2c8-6445056db83f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,\n",
    "                    'test': test_counts},\n",
    "             index=class_names\n",
    "            ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "iGS02IvfaJf1",
    "outputId": "6f7bb82c-7db9-45a9-a9d8-ad80a152ec2d"
   },
   "outputs": [],
   "source": [
    "plt.pie(train_counts,\n",
    "        explode=(0, 0,0,0,0,0,0,0,0,0,0,0) ,\n",
    "        labels=class_names,\n",
    "        autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjvvUfHhaJf1"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCMIyEESaJf2"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Dt9bQv5aJf2"
   },
   "outputs": [],
   "source": [
    "def display_random_image(class_names, images, labels):\n",
    "\n",
    "\n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "3_A4BxtXaJf2",
    "outputId": "917b3e82-018a-4b8e-ccc1-cd6d1b317d49"
   },
   "outputs": [],
   "source": [
    "display_random_image(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFnggbV0aJf2"
   },
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, labels):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"images of the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "CKSFa1xpaJf2",
    "outputId": "2b28c16c-2c75-49d0-d24d-f2b867858e2b"
   },
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Cropping2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Hyperparameters\n",
    "LATENT_DIM = 100\n",
    "IMAGE_SHAPE = (150, 150, 3)\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Generator\n",
    "def build_generator():\n",
    "    model = Sequential([\n",
    "        Input(shape=(LATENT_DIM,)),\n",
    "        Dense(128 * 38 * 38, activation=\"relu\"),\n",
    "        Reshape((38, 38, 128)),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Conv2D(3, kernel_size=3, padding='same', activation='tanh'),\n",
    "        Cropping2D(cropping=((1, 1), (1, 1)))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    model = Sequential([\n",
    "        Input(shape=IMAGE_SHAPE),\n",
    "        Conv2D(64, kernel_size=3, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(LATENT_DIM,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = tf.keras.models.Model(gan_input, gan_output)\n",
    "    return gan\n",
    "\n",
    "# Initialize models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Training GAN\n",
    "def train_gan(generator, discriminator, gan, epochs, batch_size, train_images):\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train Discriminator\n",
    "        idx = np.random.randint(0, train_images.shape[0], half_batch)\n",
    "        real_images = train_images[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (half_batch, LATENT_DIM))\n",
    "        fake_images = generator.predict(noise)\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, LATENT_DIM))\n",
    "        valid_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]:.4f}, G Loss: {g_loss:.4f}\")\n",
    "\n",
    "# Load and preprocess data\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "train_images = (train_images - 0.5) * 2.0  # Normalize to [-1, 1]\n",
    "\n",
    "# Resize images in batches\n",
    "def resize_images_in_batches(images, target_size):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_images.append(tf.image.resize(img, target_size))\n",
    "    return np.array(resized_images)\n",
    "\n",
    "train_images = resize_images_in_batches(train_images, (150, 150))\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, EPOCHS, BATCH_SIZE, train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model\n",
    "classification_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SHAPE),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "classification_model.compile(optimizer='adam',\n",
    "                             loss='sparse_categorical_crossentropy',\n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "# Train classifier on augmented dataset\n",
    "noise = np.random.normal(0, 1, (len(train_images), LATENT_DIM))\n",
    "generated_images = generator.predict(noise)\n",
    "generated_images = (generated_images + 1.0) / 2.0\n",
    "\n",
    "augmented_images = np.concatenate((train_images, generated_images))\n",
    "augmented_labels = np.concatenate((train_labels, train_labels))\n",
    "\n",
    "history =classification_model.fit(augmented_images, augmented_labels, epochs=10, batch_size=BATCH_SIZE, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vC64Q572aJf3",
    "outputId": "111b3bb9-0e89-4ff4-b199-abe063d32ca7"
   },
   "outputs": [],
   "source": [
    "#history = classification_model.fit(augmented_images, augmented_labels, epochs=10, batch_size=BATCH_SIZE, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adjc0GaoaJf3"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "aEuu2sPSaJf3",
    "outputId": "1e1cf70a-0159-4234-f9b7-1db5af0bdc0d"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNbr_LmOaJf3",
    "outputId": "e642167d-a93f-40f7-ae3b-73105f05ab75"
   },
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "YyhUMeg4aJf3",
    "outputId": "496fad6b-6c55-4745-8194-96e56aca4e38"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)     # Vector of probabilities\n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n",
    "\n",
    "display_random_image(class_names, test_images, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def seg():\n",
    "\n",
    "\n",
    "    gray = rgb2gray(img)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for i in range(8):\n",
    "\n",
    "\n",
    "\n",
    "        segment1 = (gray > i*0.1)*1\n",
    "        plt.subplot(5,2,i+1)\n",
    "\n",
    "\n",
    "        plt.title(\"segmentation: >\"+str(round(i*0.1,1)))\n",
    "\n",
    "\n",
    "        plt.imshow(segment1, cmap = 'gray')\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread('C:/Users/LENOVO/Downloads/Brain tumor GAN (2)/test/abnormal/slice_086.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to smooth the image and reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply adaptive thresholding to segment the image\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "\n",
    "# Apply morphological operations to further clean up the image\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# Perform watershed segmentation\n",
    "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "# Label markers for watershed segmentation\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "# Apply watershed segmentation\n",
    "markers = cv2.watershed(image, markers)\n",
    "image[markers == -1] = [255, 0, 0]  # Highlight damaged parts in blue\n",
    "\n",
    "# Segmentation function (You need to implement this)\n",
    "# Segmentation function\n",
    "def seg(image):\n",
    "    # Your segmentation logic here\n",
    "    # Example: using Canny edge detection\n",
    "    segmented_img = cv2.Canny(image, 100, 200)\n",
    "    return segmented_img\n",
    "\n",
    "segmented_img = seg(image)  # Call the seg function with the image variable\n",
    "print(\"Segmented Image Shape:\", segmented_img.shape)  # Check shape\n",
    "\n",
    "# Display the segmented image\n",
    "plt.figure()\n",
    "plt.imshow(segmented_img, cmap='gray')  # Assuming segmented image is grayscale\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(False)\n",
    "plt.title('Segmented Image')\n",
    "plt.show()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "index = np.random.randint(test_images.shape[0])\n",
    "plt.figure()\n",
    "plt.imshow(test_images[index])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(False)\n",
    "plt.title('Image #{} : '.format(index) + class_names[pred_labels[index]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_labels, pred_labels)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True,\n",
    "           annot_kws={\"size\": 10},\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true contains true labels and y_pred contains predicted labels\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n Classification report : \\n {}\".format(classification_report(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming test_labels and pred_labels are available\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(test_labels, pred_labels, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(report_df.iloc[:-1, :].astype(float), annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title('Classification Report')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_vgg.weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json=model.to_json()\n",
    "with open(\"model_vgg.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "from flask import Flask, render_template, request, send_from_directory\n",
    "\n",
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "STATIC_FOLDER = \"static\"\n",
    "\n",
    "json_file = open('model_vgg.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "#cnn_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#cnn_model.load_weights(\"model_vgg.weights.h5\")\n",
    "# Load model\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "\n",
    "# Preprocess an image\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "# Read the image from path and preprocess\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "# Predict & classify image\n",
    "def classify(model, image_path):\n",
    "    preprocessed_image = load_and_preprocess_image(image_path)\n",
    "    preprocessed_image = tf.reshape(preprocessed_image, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    prob = model.predict(preprocessed_image)[0]\n",
    "    print(prob)\n",
    "    # Get the index of the maximum probability\n",
    "    predicted_label_index = np.argmax(prob)\n",
    "    # Mapping index to label name\n",
    "    label_names = ['normal','abnormal']\n",
    "    # Replace with your actual label names\n",
    "    label = label_names[predicted_label_index]\n",
    "    classified_prob = prob[predicted_label_index]\n",
    "    return label, classified_prob\n",
    "\n",
    "# home page\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"home.html\")\n",
    "\n",
    "@app.route(\"/classify\", methods=[\"POST\", \"GET\"])\n",
    "def upload_file():\n",
    "    if request.method == \"GET\":\n",
    "        return render_template(\"home.html\")\n",
    "    else:\n",
    "        file = request.files[\"image\"]\n",
    "        upload_image_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "        print(upload_image_path)\n",
    "        file.save(upload_image_path)\n",
    "        label, prob = classify(model, upload_image_path)\n",
    "        prob = round((prob * 100), 2)\n",
    "    return render_template(\n",
    "        \"classify.html\", image_file_name=file.filename, label=label, prob=prob\n",
    "    )\n",
    "\n",
    "@app.route(\"/classify/<filename>\")\n",
    "def send_file(filename):\n",
    "    return send_from_directory(UPLOAD_FOLDER, filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
