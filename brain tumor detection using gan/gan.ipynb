{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPnRE34GaJfw"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "gVeRC6aeaJfy"
   },
   "outputs": [
    {
     "ename": "ArrowKeyError",
     "evalue": "A type extension with name arrow.py_extension_type already defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01msn\u001b[39;00m; sn.set(font_scale=\u001b[32m1.4\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\rcmod.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mmpl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mset_theme\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreset_defaults\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreset_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33maxes_style\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mset_style\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplotting_context\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mset_context\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mset_palette\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     13\u001b[39m _style_keys = [\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maxes.facecolor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m \n\u001b[32m     51\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\palettes.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mmpl\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mexternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m husl\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m desaturate, get_color_cycle\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xkcd_rgb, crayons\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_colormap\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\utils.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mmpl\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_rgb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py:39\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m     41\u001b[39m     )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m     43\u001b[39m     _module = _err.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\__init__.py:27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompressors\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     pa_version_under10p1,\n\u001b[32m     29\u001b[39m     pa_version_under11p0,\n\u001b[32m     30\u001b[39m     pa_version_under13p0,\n\u001b[32m     31\u001b[39m     pa_version_under14p0,\n\u001b[32m     32\u001b[39m     pa_version_under14p1,\n\u001b[32m     33\u001b[39m     pa_version_under16p0,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\pyarrow.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpa\u001b[39;00m\n\u001b[32m     10\u001b[39m     _palv = Version(Version(pa.__version__).base_version)\n\u001b[32m     11\u001b[39m     pa_version_under10p1 = _palv < Version(\u001b[33m\"\u001b[39m\u001b[33m10.0.1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[39m\n\u001b[32m     63\u001b[39m _gc_enabled = _gc.isenabled()\n\u001b[32m     64\u001b[39m _gc.disable()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_lib\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[32m     67\u001b[39m     _gc.enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\types.pxi:5485\u001b[39m, in \u001b[36minit pyarrow.lib\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\types.pxi:5467\u001b[39m, in \u001b[36mpyarrow.lib._register_py_extension_type\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: A type extension with name arrow.py_extension_type already defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WfT8PyiRaJfz"
   },
   "outputs": [],
   "source": [
    "class_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GnWSIhzaJfz"
   },
   "source": [
    "# Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d684vIT_aJfz"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    datasets = [r'C:\\Users\\mahad\\Downloads\\Brain Tumor Detection\\Brain Tumor Detection\\brain tumor detection using gan\\seg_train', r'C:\\Users\\mahad\\Downloads\\Brain Tumor Detection\\Brain Tumor Detection\\brain tumor detection using gan\\seg_test']\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        print(\"Loading {}\".format(dataset))\n",
    "\n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "\n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "\n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "\n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaUtXn7-aJf0",
    "outputId": "6210690b-7723-41d4-93ca-b164ba6ff195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\mahad\\Downloads\\Brain Tumor Detection\\Brain Tumor Detection\\brain tumor detection using gan\\seg_train\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m (train_images, train_labels), (test_images, test_labels) = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m label = class_names_label[folder]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Iterate through each image in our folder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(os.listdir(os.path.join(dataset, folder))):\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Get the path name of the image\u001b[39;00m\n\u001b[32m     23\u001b[39m     img_path = os.path.join(os.path.join(dataset, folder), file)\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Open and resize the img\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt_whTHjaJf0"
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVk4qT3JaJf0",
    "outputId": "c222462f-c397-4d39-ce94-9110589abebd"
   },
   "outputs": [],
   "source": [
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each image is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "y84npp_faJf1",
    "outputId": "ac69b741-7d62-4d71-b2c8-6445056db83f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,\n",
    "                    'test': test_counts},\n",
    "             index=class_names\n",
    "            ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "iGS02IvfaJf1",
    "outputId": "6f7bb82c-7db9-45a9-a9d8-ad80a152ec2d"
   },
   "outputs": [],
   "source": [
    "plt.pie(train_counts,\n",
    "        explode=(0, 0,0,0) ,\n",
    "        labels=class_names,\n",
    "        autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjvvUfHhaJf1"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCMIyEESaJf2"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Dt9bQv5aJf2"
   },
   "outputs": [],
   "source": [
    "def display_random_image(class_names, images, labels):\n",
    "\n",
    "\n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "3_A4BxtXaJf2",
    "outputId": "917b3e82-018a-4b8e-ccc1-cd6d1b317d49"
   },
   "outputs": [],
   "source": [
    "display_random_image(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFnggbV0aJf2"
   },
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, labels):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"images of the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "CKSFa1xpaJf2",
    "outputId": "2b28c16c-2c75-49d0-d24d-f2b867858e2b"
   },
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =15\n",
    "epochs = 10\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# anomaly detection\n",
    "def build_gan(latent_dim, input_shape):\n",
    "    input_layer = Input(shape=(latent_dim,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "    output_layer = Reshape(input_shape)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def build_discriminator(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Flatten()(input_layer)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Combine the generator and discriminator into a GAN\n",
    "def build_anomaly_detector(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    generated_image = generator(gan_input)\n",
    "    gan_output = discriminator(generated_image)\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    return gan\n",
    "\n",
    "normal_data = train_images\n",
    "\n",
    "\n",
    "normal_data = (train_images.astype(np.float16) - 127.5) / 127.5\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1000)\n",
    "tf.random.set_seed(1000)\n",
    "latent_dim = 100\n",
    "input_shape = normal_data.shape[1:]\n",
    "\n",
    "generator = build_gan(latent_dim, input_shape)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan = build_anomaly_detector(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a random batch of normal data\n",
    "    idx = np.random.randint(0, normal_data.shape[0], batch_size)\n",
    "    real_images = normal_data[idx]\n",
    "\n",
    "    # Generate a batch of fake images\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train the generator (discriminator weights are frozen)\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    # Print progress and save generated images at checkpoints\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        # Generate and save generated images\n",
    "        generated_images = generator.predict(np.random.normal(0, 1, (16, latent_dim)))\n",
    "        generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "        fig, axs = plt.subplots(4, 4, figsize=(4, 4))\n",
    "        cnt = 0\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                axs[i, j].imshow(generated_images[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "       \n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation= 'relu'),\n",
    "            tf.keras.layers.Dense(14, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vC64Q572aJf3",
    "outputId": "111b3bb9-0e89-4ff4-b199-abe063d32ca7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adjc0GaoaJf3"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "aEuu2sPSaJf3",
    "outputId": "1e1cf70a-0159-4234-f9b7-1db5af0bdc0d"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNbr_LmOaJf3",
    "outputId": "e642167d-a93f-40f7-ae3b-73105f05ab75"
   },
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "YyhUMeg4aJf3",
    "outputId": "496fad6b-6c55-4745-8194-96e56aca4e38"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)     # Vector of probabilities\n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n",
    "\n",
    "display_random_image(class_names, test_images, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_labels, pred_labels)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True,\n",
    "           annot_kws={\"size\": 10},\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true contains true labels and y_pred contains predicted labels\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n Classification report : \\n {}\".format(classification_report(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming test_labels and pred_labels are available\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(test_labels, pred_labels, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(report_df.iloc[:-1, :].astype(float), annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title('Classification Report')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_vgg_full.h5\")\n",
    "print(\"âœ… Full model (architecture + weights) saved to model_vgg_full.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 17:58:41] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 17:58:41] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 17:58:41] \"\u001b[33mGET /static/images/bg.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 17:58:41] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /classify [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahad\\AppData\\Local\\Temp\\ipykernel_20376\\1174880248.py\", line 62, in upload_file\n",
      "    file.save(upload_image_path)\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\werkzeug\\datastructures\\file_storage.py\", line 125, in save\n",
      "    dst = open(dst, \"wb\")\n",
      "          ^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'uploads\\\\'\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 17:59:38] \"\u001b[35m\u001b[1mPOST /classify HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Exception on /classify [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahad\\AppData\\Local\\Temp\\ipykernel_20376\\1174880248.py\", line 63, in upload_file\n",
      "    label, prob = classify(model, upload_image_path)\n",
      "                           ^^^^^\n",
      "NameError: name 'model' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:00:13] \"\u001b[35m\u001b[1mPOST /classify HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads\\gg (6).jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:01:47] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:01:47] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:01:47] \"\u001b[33mGET /static/images/bg.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:01:47] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /classify [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahad\\AppData\\Local\\Temp\\ipykernel_20376\\1174880248.py\", line 63, in upload_file\n",
      "    label, prob = classify(model, upload_image_path)\n",
      "                           ^^^^^\n",
      "NameError: name 'model' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:01:54] \"\u001b[35m\u001b[1mPOST /classify HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads\\gg (4).jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Exception on /classify [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahad\\AppData\\Local\\Temp\\ipykernel_20376\\1174880248.py\", line 63, in upload_file\n",
      "    label, prob = classify(model, upload_image_path)\n",
      "                           ^^^^^\n",
      "NameError: name 'model' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [02/Aug/2025 18:02:08] \"\u001b[35m\u001b[1mPOST /classify HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads\\2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "from flask import Flask, render_template, request, send_from_directory\n",
    "\n",
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "STATIC_FOLDER = \"static\"\n",
    "\n",
    "from keras.models import load_model\n",
    "cnn_model = load_model(\"model_vgg_full.h5\")\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "# Preprocess an image\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "# Read the image from path and preprocess\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "# Predict & classify image\n",
    "def classify(model, image_path):\n",
    "    preprocessed_image = load_and_preprocess_image(image_path)\n",
    "    preprocessed_image = tf.reshape(preprocessed_image, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    prob = model.predict(preprocessed_image)[0]\n",
    "    print(prob)\n",
    "    # Get the index of the maximum probability\n",
    "    predicted_label_index = np.argmax(prob)\n",
    "    # Mapping index to label name\n",
    "    label_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "    # Replace with your actual label names\n",
    "    label = label_names[predicted_label_index]\n",
    "    classified_prob = prob[predicted_label_index]\n",
    "    return label, classified_prob\n",
    "\n",
    "# home page\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"home.html\")\n",
    "\n",
    "@app.route(\"/classify\", methods=[\"POST\", \"GET\"])\n",
    "def upload_file():\n",
    "    if request.method == \"GET\":\n",
    "        return render_template(\"home.html\")\n",
    "    else:\n",
    "        file = request.files[\"image\"]\n",
    "        upload_image_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "        print(upload_image_path)\n",
    "        file.save(upload_image_path)\n",
    "        label, prob = classify(model, upload_image_path)\n",
    "        prob = round((prob * 100), 2)\n",
    "    return render_template(\n",
    "        \"classify.html\", image_file_name=file.filename, label=label, prob=prob\n",
    "    )\n",
    "\n",
    "@app.route(\"/classify/<filename>\")\n",
    "def send_file(filename):\n",
    "    return send_from_directory(UPLOAD_FOLDER, filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
